{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1b20ee",
   "metadata": {},
   "source": [
    "# Submission 2: Denoising Autoencoders\n",
    "Trains CNN autoencoders to denoise pneumonia images based on [Medical image denoising using convolutional denoising autoencoders](https://arxiv.org/pdf/1608.04667.pdf). Contains 3 CNN autoencoders:\n",
    "1. Autoencoder for denoising noisy images with lambda = 25\n",
    "2. Autoencoder for denoising noisy images with lambda = 50\n",
    "3. Autoencoder for denoising noisy images with lambda = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68dde9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac2613",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9627b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ds_path = r\"datasets/pneumonia\"\n",
    "original_ds_filenames = os.listdir(original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e6f85d-2e5a-43a6-99ca-c241916dbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of clean (no noise) pneumonia images\n",
    "class CleanDataset(Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.DataFrame([filename for filename in original_ds_filenames])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.img_labels.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "        \n",
    "        # Read image and label/filename\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccf66d3-023a-4f59-94aa-81a86a268f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_ds = CleanDataset(img_dir=original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3078df92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get indices to split data into 80% training and 20% test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_filenames, test_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_ds_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generate training and test sets from indices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m Subset(original_ds, train_filenames)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Get indices to split data into 80% training and 20% test data\n",
    "train_filenames, test_filenames = train_test_split(original_ds_filenames, train_size=0.8, random_state=0)\n",
    "\n",
    "# Generate training and test sets from indices\n",
    "train_ds = Subset(original_ds, train_filenames)\n",
    "test_ds = Subset(original_ds, test_filenames)\n",
    "\n",
    "print(f\"Training samples: {len(train_ds)} ({len(train_ds)/len(original_ds)*100}% of data)\")\n",
    "print(f\"Test samples: {len(test_ds)} ({len(test_ds)/len(original_ds)*100}% of data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ca378",
   "metadata": {},
   "source": [
    "### Generating Noisy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930fbd7-1c03-40b4-82ab-09e4f8f76a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of noisy pneumonia images\n",
    "class NoisyDataset(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43454455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDatasetRGB(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            # transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbe820-9d51-4d5b-b0b9-2d5f239de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 sets of noisy images based on the original dataset\n",
    "noisy25_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy25_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e252571-1b4d-4e9f-9b89-2768ea495ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "loader = DataLoader(noisy75_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70741a57-e1f4-4bf6-8892-e7ef0d2f4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display images with and without noise\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "print(noisy_imgs[0].size())\n",
    "\n",
    "noisy_img = torch.reshape(noisy_imgs[0], (64, 64, 1))\n",
    "clean_img = torch.reshape(clean_imgs[0], (64, 64, 1))\n",
    "\n",
    "imgs = [noisy_img, clean_img]\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 2, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgs[i-1].squeeze(), cmap=\"grey\")\n",
    "\n",
    "print(\"With Noise (Left) vs Without Noise (Right) in noisy dataset with lambda = 75\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddced7-820f-43ec-9cd0-709d20f9dcae",
   "metadata": {},
   "source": [
    "### Training CNN Autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f27155-2a27-4e5c-87f2-4f95e1980fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # Example for grayscale images, change channels accordingly\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Use sigmoid for [0,1] scaled images\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa54c56-b146-46b6-a000-2492a1339f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Func\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0511e40-4c07-4c1d-b047-3f1587b0438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train Model\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# # Example for one set, repeat for each noise level dataset\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# criterion = nn.MSELoss()\n",
    "\n",
    "# model_25 = CNNAutoencoder().to(device)\n",
    "# optimizer_25 = optim.Adam(model_25.parameters(), lr=0.001)\n",
    "# dataloader_25 = DataLoader(noisy25_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# model_50 = CNNAutoencoder().to(device)\n",
    "# optimizer_50 = optim.Adam(model_50.parameters(), lr=0.001)\n",
    "# dataloader_50 = DataLoader(noisy50_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# model_75 = CNNAutoencoder().to(device)\n",
    "# optimizer_75 = optim.Adam(model_75.parameters(), lr=0.001)\n",
    "# dataloader_75 = DataLoader(noisy75_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "# # Train each model\n",
    "# train_model(model_25, dataloader_25, criterion, optimizer_25, num_epochs=25)\n",
    "# train_model(model_50, dataloader_50, criterion, optimizer_50, num_epochs=25)\n",
    "# train_model(model_75, dataloader_75, criterion, optimizer_75, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63829813",
   "metadata": {},
   "source": [
    "## Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b19b",
   "metadata": {},
   "source": [
    "Evaluate your results against the test images by running the error term you used in submission 1 against each model compared with the 4 other classical methods. The result should be the average error value for each configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters from submission 1\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"images/noisy.png\")\n",
    "# pyplot.imshow(img)\n",
    "\n",
    "# median filter\n",
    "def median(img):\n",
    "    kernel_size = 3\n",
    "    median_filter = cv.medianBlur(img, kernel_size)\n",
    "    # median_filter = cv.cvtColor(median_filter, cv.COLOR_BGR2GRAY)\n",
    "    return median_filter\n",
    "# pyplot.imshow(median_filter)\n",
    "\n",
    "# mean filter\n",
    "def mean(img):\n",
    "    kernel_size = [3, 3]\n",
    "    mean_filter = cv.blur(img, kernel_size)\n",
    "    # mean_filter = cv.cvtColor(mean_filter, cv.COLOR_BGR2GRAY)\n",
    "    return mean_filter\n",
    "# pyplot.imshow(mean_filter)\n",
    "\n",
    "# bilateral filter\n",
    "def bilat(img):\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    size = 15\n",
    "    sigma_color = 75\n",
    "    sigma_space = 75\n",
    "    bilateral_filter = cv.bilateralFilter(img_rgb, size, sigma_color, sigma_space)\n",
    "    # bilateral_filter = cv.cvtColor(bilateral_filter, cv.COLOR_BGR2GRAY)\n",
    "    return bilateral_filter\n",
    "# pyplot.imshow(bilateral_filter)\n",
    "\n",
    "# gaussian blur filter\n",
    "def gauss(img):\n",
    "    kernel_size = [5, 5]\n",
    "    std_dev = 0 #passing 0 will make function auto compute std dev\n",
    "    gauss_blur = cv.GaussianBlur(img,kernel_size,std_dev)\n",
    "    # gauss_blur = cv.cvtColor(gauss_blur, cv.COLOR_BGR2GRAY)\n",
    "    return gauss_blur\n",
    "# pyplot.imshow(gauss_blur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195501ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error function from submission 1\n",
    "def mse(img_a, img_b):\n",
    "    h, w = img_a.shape\n",
    "    diff = cv.subtract(img_a, img_b)\n",
    "    err = np.sum(diff**2)\n",
    "    mse = err/(float(h*w))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c62156",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = DataLoader(noisy25_ds, batch_size=16)\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "noisy_imgs = noisy_imgs.numpy()\n",
    "clean_imgs = clean_imgs.numpy()\n",
    "\n",
    "median_score = 0\n",
    "mean_score = 0\n",
    "bilat_score = 0\n",
    "gauss_score = 0\n",
    "for image_n, image_c in zip(noisy_imgs, clean_imgs):\n",
    "    img_median = median(image_c)\n",
    "    img_mean = mean(image_c)\n",
    "    img_bilat = bilat(image_c)\n",
    "    img_gauss = gauss(image_c)\n",
    "    median_eval = mse(image_c, img_median)\n",
    "    mean_eval = mse(image_c, img_mean)\n",
    "    bilat_eval = mse(image_c, img_bilat)\n",
    "    gauss_eval = mse(image_c, img_gauss)\n",
    "    median_score += median_eval\n",
    "    mean_score += mean_eval\n",
    "    bilat_score += bilat_eval\n",
    "    gauss_score += gauss_eval\n",
    "median_score = median_score/len(noisy_imgs)\n",
    "mean_score = mean_score/len(noisy_imgs)\n",
    "bilat_score = bilat_score/len(noisy_imgs)\n",
    "gauss_score = gauss_score/len(noisy_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e4495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use mse function\n",
    "\n",
    "median_eval = mse(img_clear, img_median)\n",
    "print('MEDIAN eval error: ', median_eval)\n",
    "\n",
    "mean_eval = mse(img_clear, img_mean)\n",
    "print('MEAN eval error: ', mean_eval)\n",
    "\n",
    "bilat_eval = mse(img_clear, img_bilat)\n",
    "print('BILATERAL eval error: ', bilat_eval)\n",
    "\n",
    "gauss_eval = mse(img_clear, img_gauss)\n",
    "print('GAUSSIAN eval error: ', gauss_eval)\n",
    "\n",
    "# model25\n",
    "\n",
    "\n",
    "# model50\n",
    "\n",
    "\n",
    "# model75\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48ce62a7",
   "metadata": {},
   "source": [
    "**Why is poisson distribution the ideal one to use to simulate noise for medical images? Why not gaussian or something else? Answer in terms of relevance of medical applications.**\n",
    "\n",
    "The Poisson distribution stands out as the go-to model for simulating noise in medical images due to its close match to the random nature of photon detection, particularly in imaging methods like X-ray and PET scans. It excels in accurately representing situations with low photon counts, which are common in medical imaging, especially when using low radiation doses or capturing areas with minimal tissue density. Moreover, its ability to reflect changes in noise levels according to signal intensity mirrors the real-world behavior seen in medical images. The discrete nature of the Poisson distribution suits the whole number pixel values typical in medical imaging, and it maintains the clarity of edges better compared to the Gaussian distribution. Its solid theoretical grounding in photon counting processes also ensures that the simulated noise aligns well with the statistical properties of actual medical images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c28e18",
   "metadata": {},
   "source": [
    "**Which one performed the best? Why do you think this is the case?**\n",
    "\n",
    "The Bilaterial filter had the best balance between noise reduction and detial preservation. We believe its because it manages to preserve the edge, does selective smoothing, and is very intuitive. It's also very robust."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
