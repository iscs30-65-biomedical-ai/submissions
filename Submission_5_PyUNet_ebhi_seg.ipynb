{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0oFTByKqb1Lg"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "model_type = \"unet_attn_dp\"\n",
        "loss_type = \"CE\"\n",
        "cfg_file = \"config.json\"\n",
        "\n",
        "params = {\n",
        "  \"img_width\": 128,\n",
        "  \"img_height\": 128,\n",
        "  \"batch_size\": 2,\n",
        "  \"epochs\": 100,\n",
        "  \"learning_rate\": 0.0001,\n",
        "  \"in_channels\": 3,\n",
        "  \"out_channels\": 2,\n",
        "  \"loss_type\": loss_type,\n",
        "  \"model_type\": model_type,\n",
        "  \"device\": \"cpu\",\n",
        "  \"gpu_index\": 0,\n",
        "  \"cont\": False,\n",
        "  \"input_img_dir\": \"train/images\",\n",
        "  \"input_mask_dir\": \"train/masks\",\n",
        "  \"model_file\": f\"{model_type}.pth\"\n",
        "}\n",
        "\n",
        "with open(cfg_file, \"w\") as outfile:\n",
        "    # json_data refers to the above JSON\n",
        "    json.dump(params, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVMxfwktc4Rw",
        "outputId": "e277fbea-e41a-40d1-cffd-8de30bdc551a"
      },
      "outputs": [],
      "source": [
        "# %cd /content/pyunet\n",
        "# !pip install onnxruntime\n",
        "# !pip install pytorch_msssim\n",
        "!python -m pyunet --mode train --config-file config.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NbTL0us4lmY"
      },
      "outputs": [],
      "source": [
        "cfg_benchmark_file = \"sample-pair.json\"\n",
        "\n",
        "params = {\n",
        "  \"img_width\": 128,\n",
        "  \"img_height\": 128,\n",
        "  \"input_img_dir\": \"train/images\",\n",
        "  \"input_mask_dir\": \"train/masks\",\n",
        "  \"device\": \"cpu\",\n",
        "  \"gpu_index\": 0,\n",
        "  \"sampled_index\": -1,\n",
        "  \"in_channels\": 3,\n",
        "  \"out_channels\": 2,\n",
        "  \"models\": [\n",
        "    {\n",
        "      \"type\": \"unet\",\n",
        "      \"file\": \"unet.pth\"\n",
        "    },\n",
        "    {\n",
        "      \"type\": \"unet_attn\",\n",
        "      \"file\": \"unet_attn.pth\"\n",
        "    },\n",
        "    {\n",
        "      \"type\": \"unet_attn_ghost\",\n",
        "      \"file\": \"unet_attn_ghost.pth\"\n",
        "    }\n",
        "  ]\n",
        "}\n",
        "\n",
        "with open(cfg_benchmark_file, \"w\") as outfile:\n",
        "    # json_data refers to the above JSON\n",
        "    json.dump(params, outfile)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeMjR75G4uXT",
        "outputId": "fd1fe375-1cae-431a-8d45-b14404da4795"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "In Channels: 3\n",
            "Out Channels: 2\n",
            "Sampling pair...\n",
            "input_img_dir: train/images\n",
            "input_mask_dir: train/masks\n",
            "sampled_index: 296\n",
            "train/images\\gtxc2110507-1-400-009.png\n",
            "train/masks\\gtxc2110507-1-400-009.tiff\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-20 12:26:11.158970: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "WARNING:tensorflow:From C:\\Users\\pamel\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"c:\\Users\\pamel\\OneDrive\\Desktop\\ISCS30.65-M1\\submissions\\pyunet\\__main__.py\", line 342, in <module>\n",
            "    main()\n",
            "  File \"c:\\Users\\pamel\\OneDrive\\Desktop\\ISCS30.65-M1\\submissions\\pyunet\\__main__.py\", line 236, in main\n",
            "    cmd.execute()\n",
            "  File \"c:\\Users\\pamel\\OneDrive\\Desktop\\ISCS30.65-M1\\submissions\\pyunet\\.\\modules\\sample_pair.py\", line 93, in execute\n",
            "    print(\"CUDA Device: {}\".format(torch.cuda.get_device_name(self.gpu_index)))\n",
            "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\pamel\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py\", line 423, in get_device_name\n",
            "    return get_device_properties(device).name\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\pamel\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py\", line 453, in get_device_properties\n",
            "    _lazy_init()  # will define _get_device_properties\n",
            "    ^^^^^^^^^^^^\n",
            "  File \"C:\\Users\\pamel\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\cuda\\__init__.py\", line 293, in _lazy_init\n",
            "    raise AssertionError(\"Torch not compiled with CUDA enabled\")\n",
            "AssertionError: Torch not compiled with CUDA enabled\n"
          ]
        }
      ],
      "source": [
        "# %cd /content/pyunet\n",
        "!python -m pyunet --mode sample-pair --config-file sample-pair.json"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
