{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1b20ee",
   "metadata": {},
   "source": [
    "## Submission 3: Relevance of Latent Space\n",
    "Trains CNN autoencoders to denoise pneumonia images based on [Medical image denoising using convolutional denoising autoencoders](https://arxiv.org/pdf/1608.04667.pdf). Contains 3 CNN autoencoders:\n",
    "1. Autoencoder for denoising noisy images with lambda = 25\n",
    "2. Autoencoder for denoising noisy images with lambda = 50\n",
    "3. Autoencoder for denoising noisy images with lambda = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68dde9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d00f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac2613",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9627b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ds_path = r\"datasets/pneumonia\"\n",
    "original_ds_filenames = os.listdir(original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25e6f85d-2e5a-43a6-99ca-c241916dbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of clean (no noise) pneumonia images\n",
    "class CleanDataset(Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.DataFrame([filename for filename in original_ds_filenames])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.img_labels.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "        \n",
    "        # Read image and label/filename\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ccf66d3-023a-4f59-94aa-81a86a268f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_ds = CleanDataset(img_dir=original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3078df92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 1850 (79.98270644185041% of data)\n",
      "Test samples: 463 (20.01729355814959% of data)\n"
     ]
    }
   ],
   "source": [
    "# Get indices to split data into 80% training and 20% test data\n",
    "train_filenames, test_filenames = train_test_split(original_ds_filenames, train_size=0.8, random_state=0)\n",
    "\n",
    "# Generate training and test sets from indices\n",
    "train_ds = Subset(original_ds, train_filenames)\n",
    "test_ds = Subset(original_ds, test_filenames)\n",
    "\n",
    "print(f\"Training samples: {len(train_ds)} ({len(train_ds)/len(original_ds)*100}% of data)\")\n",
    "print(f\"Test samples: {len(test_ds)} ({len(test_ds)/len(original_ds)*100}% of data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ca378",
   "metadata": {},
   "source": [
    "### Generating Noisy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c930fbd7-1c03-40b4-82ab-09e4f8f76a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of noisy pneumonia images\n",
    "class NoisyDataset(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "43454455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDatasetRGB(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            # transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7bbe820-9d51-4d5b-b0b9-2d5f239de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 sets of noisy images based on the original dataset\n",
    "noisy25_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03b7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy25_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e252571-1b4d-4e9f-9b89-2768ea495ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "loader = DataLoader(noisy75_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70741a57-e1f4-4bf6-8892-e7ef0d2f4680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "'grey' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     figure\u001b[38;5;241m.\u001b[39madd_subplot(rows, cols, i)\n\u001b[0;32m     15\u001b[0m     plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 16\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimgs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrey\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith Noise (Left) vs Without Noise (Right) in noisy dataset with lambda = 75\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:2652\u001b[0m, in \u001b[0;36mimshow\u001b[1;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[0;32m   2646\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[0;32m   2647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[0;32m   2648\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   2649\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   2650\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[0;32m   2651\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m-> 2652\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m gca()\u001b[38;5;241m.\u001b[39mimshow(\n\u001b[0;32m   2653\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm, aspect\u001b[38;5;241m=\u001b[39maspect,\n\u001b[0;32m   2654\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation, alpha\u001b[38;5;241m=\u001b[39malpha, vmin\u001b[38;5;241m=\u001b[39mvmin,\n\u001b[0;32m   2655\u001b[0m         vmax\u001b[38;5;241m=\u001b[39mvmax, origin\u001b[38;5;241m=\u001b[39morigin, extent\u001b[38;5;241m=\u001b[39mextent,\n\u001b[0;32m   2656\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   2657\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm, filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   2658\u001b[0m         url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m: data} \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}),\n\u001b[0;32m   2659\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2660\u001b[0m     sci(__ret)\n\u001b[0;32m   2661\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\deprecation.py:459\u001b[0m, in \u001b[0;36mmake_keyword_only.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m name_idx:\n\u001b[0;32m    454\u001b[0m     warn_deprecated(\n\u001b[0;32m    455\u001b[0m         since, message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing the \u001b[39m\u001b[38;5;132;01m%(name)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%(obj_type)s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    456\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpositionally is deprecated since Matplotlib \u001b[39m\u001b[38;5;132;01m%(since)s\u001b[39;00m\u001b[38;5;124m; the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    457\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter will become keyword-only \u001b[39m\u001b[38;5;132;01m%(removal)s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    458\u001b[0m         name\u001b[38;5;241m=\u001b[39mname, obj_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py:1412\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1411\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1412\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(ax, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mmap\u001b[39m(sanitize_sequence, args), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1414\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1415\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[0;32m   1416\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py:5475\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[1;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[0;32m   5473\u001b[0m     aspect \u001b[38;5;241m=\u001b[39m rcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.aspect\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m   5474\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m-> 5475\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap, norm, interpolation,\n\u001b[0;32m   5476\u001b[0m                       origin, extent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m   5477\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m   5478\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m   5479\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   5481\u001b[0m im\u001b[38;5;241m.\u001b[39mset_data(X)\n\u001b[0;32m   5482\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py:929\u001b[0m, in \u001b[0;36mAxesImage.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, extent, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ax,\n\u001b[0;32m    914\u001b[0m              cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    915\u001b[0m              norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    924\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    925\u001b[0m              ):\n\u001b[0;32m    927\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_extent \u001b[38;5;241m=\u001b[39m extent\n\u001b[1;32m--> 929\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    930\u001b[0m         ax,\n\u001b[0;32m    931\u001b[0m         cmap\u001b[38;5;241m=\u001b[39mcmap,\n\u001b[0;32m    932\u001b[0m         norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[0;32m    933\u001b[0m         interpolation\u001b[38;5;241m=\u001b[39minterpolation,\n\u001b[0;32m    934\u001b[0m         origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[0;32m    935\u001b[0m         filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[0;32m    936\u001b[0m         filterrad\u001b[38;5;241m=\u001b[39mfilterrad,\n\u001b[0;32m    937\u001b[0m         resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[0;32m    938\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[0;32m    939\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    940\u001b[0m     )\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\image.py:246\u001b[0m, in \u001b[0;36m_ImageBase.__init__\u001b[1;34m(self, ax, cmap, norm, interpolation, origin, filternorm, filterrad, resample, interpolation_stage, **kwargs)\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, ax,\n\u001b[0;32m    234\u001b[0m              cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    235\u001b[0m              norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    243\u001b[0m              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    244\u001b[0m              ):\n\u001b[0;32m    245\u001b[0m     martist\u001b[38;5;241m.\u001b[39mArtist\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m--> 246\u001b[0m     \u001b[43mcm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScalarMappable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    247\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m origin \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m         origin \u001b[38;5;241m=\u001b[39m mpl\u001b[38;5;241m.\u001b[39mrcParams[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.origin\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py:359\u001b[0m, in \u001b[0;36mScalarMappable.__init__\u001b[1;34m(self, norm, cmap)\u001b[0m\n\u001b[0;32m    357\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_norm(norm)  \u001b[38;5;66;03m# The Normalize instance of this ScalarMappable.\u001b[39;00m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# So that the setter knows we're initializing.\u001b[39;00m\n\u001b[1;32m--> 359\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_cmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# The Colormap instance of this ScalarMappable.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;66;03m#: The last colorbar associated with this ScalarMappable. May be None.\u001b[39;00m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolorbar \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py:546\u001b[0m, in \u001b[0;36mScalarMappable.set_cmap\u001b[1;34m(self, cmap)\u001b[0m\n\u001b[0;32m    538\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    539\u001b[0m \u001b[38;5;124;03mSet the colormap for luminance data.\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;124;03mcmap : `.Colormap` or str or None\u001b[39;00m\n\u001b[0;32m    544\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    545\u001b[0m in_init \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmap \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 546\u001b[0m cmap \u001b[38;5;241m=\u001b[39m \u001b[43mget_cmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmap\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcmap \u001b[38;5;241m=\u001b[39m cmap\n\u001b[0;32m    548\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m in_init:\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\cm.py:286\u001b[0m, in \u001b[0;36mget_cmap\u001b[1;34m(name, lut)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, colors\u001b[38;5;241m.\u001b[39mColormap):\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m name\n\u001b[1;32m--> 286\u001b[0m \u001b[43m_api\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_in_list\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_cmap_registry\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lut \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cmap_registry[name]\n",
      "File \u001b[1;32mc:\\ProgramData\\Anaconda3\\lib\\site-packages\\matplotlib\\_api\\__init__.py:129\u001b[0m, in \u001b[0;36mcheck_in_list\u001b[1;34m(_values, _print_supported_values, **kwargs)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _print_supported_values:\n\u001b[0;32m    128\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m; supported values are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mrepr\u001b[39m,\u001b[38;5;250m \u001b[39mvalues))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 129\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: 'grey' is not a valid value for name; supported values are 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'inferno', 'inferno_r', 'jet', 'jet_r', 'magma', 'magma_r', 'nipy_spectral', 'nipy_spectral_r', 'ocean', 'ocean_r', 'pink', 'pink_r', 'plasma', 'plasma_r', 'prism', 'prism_r', 'rainbow', 'rainbow_r', 'seismic', 'seismic_r', 'spring', 'spring_r', 'summer', 'summer_r', 'tab10', 'tab10_r', 'tab20', 'tab20_r', 'tab20b', 'tab20b_r', 'tab20c', 'tab20c_r', 'terrain', 'terrain_r', 'turbo', 'turbo_r', 'twilight', 'twilight_r', 'twilight_shifted', 'twilight_shifted_r', 'viridis', 'viridis_r', 'winter', 'winter_r'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS0AAAEtCAYAAABd4zbuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAD8UlEQVR4nO3UQQ0AIBDAMMC/50MDL7KkVbDX9szMAog4vwMAXpgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKaYFpJgWkGJaQIppASmmBaSYFpBiWkCKaQEppgWkmBaQYlpAimkBKRcqHgZWc2K7rAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display images with and without noise\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "print(noisy_imgs[0].size())\n",
    "\n",
    "noisy_img = torch.reshape(noisy_imgs[0], (64, 64, 1))\n",
    "clean_img = torch.reshape(clean_imgs[0], (64, 64, 1))\n",
    "\n",
    "imgs = [noisy_img, clean_img]\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 2, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgs[i-1].squeeze(), cmap=\"Greys\")\n",
    "\n",
    "print(\"With Noise (Left) vs Without Noise (Right) in noisy dataset with lambda = 75\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddced7-820f-43ec-9cd0-709d20f9dcae",
   "metadata": {},
   "source": [
    "### Training CNN Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec731b6",
   "metadata": {},
   "source": [
    "1. Create a method called \"encode\" in your autoencoder model that accepts the same x (your image) but returns the the z latent space of the model. This is expected to run after you have trained the model for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f27155-2a27-4e5c-87f2-4f95e1980fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # Example for grayscale images, change channels accordingly\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Use sigmoid for [0,1] scaled images\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.relu(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa54c56-b146-46b6-a000-2492a1339f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Func\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11728645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = CNNAutoencoder().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataloader = DataLoader(original_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca117045",
   "metadata": {},
   "source": [
    "2. Using the encode method, create a dataset of z values from the original training set that you used and save it in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f180781",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_encoded_array = []\n",
    "\n",
    "# loop through the original dataset and encode each image then write to csv\n",
    "with open('encoded_images.csv', mode='w', newline='') as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  for image in original_ds:\n",
    "    z = model.encode(image)\n",
    "    # temp_encoded_array.append(z)\n",
    "    csv_writer.writerow(z)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63829813",
   "metadata": {},
   "source": [
    "## Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b19b",
   "metadata": {},
   "source": [
    "3. Research a method that determines how good your z features are. You may start with the correlation example: https://colab.research.google.com/drive/1NNH6QBlVZ4SzeLr-hDPYVEoMJ8BnAJYkLinks to an external site.Answer the following question: For this particular task,  how did you measure how good your configuration for latent space dimensionality is? Make sure your answer follows the following criteria:\n",
    "\n",
    "- Objectively sound (computationally proven)\n",
    "- Explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters from submission 1\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"images/noisy.png\")\n",
    "# pyplot.imshow(img)\n",
    "\n",
    "# median filter\n",
    "def median(img):\n",
    "    kernel_size = 3\n",
    "    median_filter = cv.medianBlur(img, kernel_size)\n",
    "    # median_filter = cv.cvtColor(median_filter, cv.COLOR_BGR2GRAY)\n",
    "    return median_filter\n",
    "# pyplot.imshow(median_filter)\n",
    "\n",
    "# mean filter\n",
    "def mean(img):\n",
    "    kernel_size = [3, 3]\n",
    "    mean_filter = cv.blur(img, kernel_size)\n",
    "    # mean_filter = cv.cvtColor(mean_filter, cv.COLOR_BGR2GRAY)\n",
    "    return mean_filter\n",
    "# pyplot.imshow(mean_filter)\n",
    "\n",
    "# bilateral filter\n",
    "def bilat(img):\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    size = 15\n",
    "    sigma_color = 75\n",
    "    sigma_space = 75\n",
    "    bilateral_filter = cv.bilateralFilter(img_rgb, size, sigma_color, sigma_space)\n",
    "    # bilateral_filter = cv.cvtColor(bilateral_filter, cv.COLOR_BGR2GRAY)\n",
    "    return bilateral_filter\n",
    "# pyplot.imshow(bilateral_filter)\n",
    "\n",
    "# gaussian blur filter\n",
    "def gauss(img):\n",
    "    kernel_size = [5, 5]\n",
    "    std_dev = 0 #passing 0 will make function auto compute std dev\n",
    "    gauss_blur = cv.GaussianBlur(img,kernel_size,std_dev)\n",
    "    # gauss_blur = cv.cvtColor(gauss_blur, cv.COLOR_BGR2GRAY)\n",
    "    return gauss_blur\n",
    "# pyplot.imshow(gauss_blur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195501ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error function from submission 1\n",
    "def mse(img_a, img_b):\n",
    "    h, w = img_a.shape\n",
    "    diff = cv.subtract(img_a, img_b)\n",
    "    err = np.sum(diff**2)\n",
    "    mse = err/(float(h*w))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c62156",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<0,2,5>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m img_median \u001b[38;5;241m=\u001b[39m median(image_c)\n\u001b[0;32m     13\u001b[0m img_mean \u001b[38;5;241m=\u001b[39m mean(image_c)\n\u001b[1;32m---> 14\u001b[0m img_bilat \u001b[38;5;241m=\u001b[39m \u001b[43mbilat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m img_gauss \u001b[38;5;241m=\u001b[39m gauss(image_c)\n\u001b[0;32m     16\u001b[0m median_eval \u001b[38;5;241m=\u001b[39m mse(image_c, img_median)\n",
      "Cell \u001b[1;32mIn[39], line 27\u001b[0m, in \u001b[0;36mbilat\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbilat\u001b[39m(img):\n\u001b[1;32m---> 27\u001b[0m     img_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     29\u001b[0m     sigma_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m75\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<0,2,5>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 64\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(noisy25_ds, batch_size=16)\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "noisy_imgs = noisy_imgs.numpy()\n",
    "clean_imgs = clean_imgs.numpy()\n",
    "\n",
    "median_score = 0\n",
    "mean_score = 0\n",
    "bilat_score = 0\n",
    "gauss_score = 0\n",
    "for image_n, image_c in zip(noisy_imgs, clean_imgs):\n",
    "    img_median = median(image_c)\n",
    "    img_mean = mean(image_c)\n",
    "    img_bilat = bilat(image_c)\n",
    "    img_gauss = gauss(image_c)\n",
    "    median_eval = mse(image_c, img_median)\n",
    "    mean_eval = mse(image_c, img_mean)\n",
    "    bilat_eval = mse(image_c, img_bilat)\n",
    "    gauss_eval = mse(image_c, img_gauss)\n",
    "    median_score += median_eval\n",
    "    mean_score += mean_eval\n",
    "    bilat_score += bilat_eval\n",
    "    gauss_score += gauss_eval\n",
    "median_score = median_score/len(noisy_imgs)\n",
    "mean_score = mean_score/len(noisy_imgs)\n",
    "bilat_score = bilat_score/len(noisy_imgs)\n",
    "gauss_score = gauss_score/len(noisy_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e4495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDIAN eval error:  26.173992555079426\n",
      "MEAN eval error:  27.833290048911397\n",
      "BILATERAL eval error:  25.093905553391334\n",
      "GAUSSIAN eval error:  27.64564125871099\n"
     ]
    }
   ],
   "source": [
    "# use mse function\n",
    "\n",
    "median_eval = mse(img_clear, img_median)\n",
    "print('MEDIAN eval error: ', median_eval)\n",
    "\n",
    "mean_eval = mse(img_clear, img_mean)\n",
    "print('MEAN eval error: ', mean_eval)\n",
    "\n",
    "bilat_eval = mse(img_clear, img_bilat)\n",
    "print('BILATERAL eval error: ', bilat_eval)\n",
    "\n",
    "gauss_eval = mse(img_clear, img_gauss)\n",
    "print('GAUSSIAN eval error: ', gauss_eval)\n",
    "\n",
    "# model25\n",
    "\n",
    "\n",
    "# model50\n",
    "\n",
    "\n",
    "# model75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
