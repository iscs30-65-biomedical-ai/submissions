{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf1b20ee",
   "metadata": {},
   "source": [
    "## Submission 3: Relevance of Latent Space\n",
    "Trains CNN autoencoders to denoise pneumonia images based on [Medical image denoising using convolutional denoising autoencoders](https://arxiv.org/pdf/1608.04667.pdf). Contains 3 CNN autoencoders:\n",
    "1. Autoencoder for denoising noisy images with lambda = 25\n",
    "2. Autoencoder for denoising noisy images with lambda = 50\n",
    "3. Autoencoder for denoising noisy images with lambda = 75"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68dde9",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00f773b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import torch.nn as nn\n",
    "from PIL import Image\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.util import random_noise\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ac2613",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9627b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_ds_path = r\"datasets/pneumonia\"\n",
    "original_ds_filenames = os.listdir(original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e6f85d-2e5a-43a6-99ca-c241916dbb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of clean (no noise) pneumonia images\n",
    "class CleanDataset(Dataset):\n",
    "    def __init__(self, img_dir):\n",
    "        self.img_dir = img_dir\n",
    "        self.img_labels = pd.DataFrame([filename for filename in original_ds_filenames])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.img_labels.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "        \n",
    "        # Read image and label/filename\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx]\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ccf66d3-023a-4f59-94aa-81a86a268f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "original_ds = CleanDataset(img_dir=original_ds_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3078df92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Get indices to split data into 80% training and 20% test data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_filenames, test_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_ds_filenames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Generate training and test sets from indices\u001b[39;00m\n\u001b[0;32m      5\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m Subset(original_ds, train_filenames)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:2660\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[1;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[0;32m   2657\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[0;32m   2659\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m-> 2660\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2661\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\n\u001b[0;32m   2662\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2664\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[0;32m   2665\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\sklearn\\model_selection\\_split.py:2308\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[1;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[0;32m   2305\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[0;32m   2307\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2308\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   2309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2311\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size, train_size)\n\u001b[0;32m   2312\u001b[0m     )\n\u001b[0;32m   2314\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[1;31mValueError\u001b[0m: With n_samples=1, test_size=None and train_size=0.8, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "# Get indices to split data into 80% training and 20% test data\n",
    "train_filenames, test_filenames = train_test_split(original_ds_filenames, train_size=0.8, random_state=0)\n",
    "\n",
    "# Generate training and test sets from indices\n",
    "train_ds = Subset(original_ds, train_filenames)\n",
    "test_ds = Subset(original_ds, test_filenames)\n",
    "\n",
    "print(f\"Training samples: {len(train_ds)} ({len(train_ds)/len(original_ds)*100}% of data)\")\n",
    "print(f\"Test samples: {len(test_ds)} ({len(test_ds)/len(original_ds)*100}% of data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ca378",
   "metadata": {},
   "source": [
    "### Generating Noisy Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c930fbd7-1c03-40b4-82ab-09e4f8f76a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset of noisy pneumonia images\n",
    "class NoisyDataset(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43454455",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoisyDatasetRGB(Dataset):\n",
    "    def __init__(self, img_dir, filenames, noise_lambda):\n",
    "        self.img_dir = img_dir\n",
    "        self.filenames = filenames\n",
    "        self.noise_lambda = noise_lambda\n",
    "        self.preprocessing = transforms.Compose([\n",
    "            transforms.Resize((64, 64)),  # Resize images to 64x64\n",
    "            # transforms.Grayscale(num_output_channels=1),  # Convert images to grayscale\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Generate image filepath\n",
    "        filename = self.filenames.iloc[idx, 0]\n",
    "        img_path = self.img_dir + \"/\" + filename\n",
    "\n",
    "        # Read image and label/filename\n",
    "        clean_img = Image.open(img_path)\n",
    "\n",
    "        # Apply preprocessing in DAE paper\n",
    "        clean_img = self.preprocessing(clean_img)\n",
    "\n",
    "        # Add noise\n",
    "        to_tensor = transforms.PILToTensor() \n",
    "        clean_img_tensor = to_tensor(clean_img).float()\n",
    "\n",
    "        noise = np.random.poisson(lam=self.noise_lambda, size=clean_img_tensor.shape).astype(np.float32)\n",
    "        noisy_img_tensor = clean_img_tensor + torch.from_numpy(noise)\n",
    "\n",
    "        noisy_img_tensor = torch.clamp(noisy_img_tensor, 0, 255)\n",
    "        \n",
    "        return noisy_img_tensor, clean_img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bbe820-9d51-4d5b-b0b9-2d5f239de2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 3 sets of noisy images based on the original dataset\n",
    "noisy25_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_ds = NoisyDataset(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b7515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy25_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 25)\n",
    "\n",
    "noisy50_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 50)\n",
    "\n",
    "noisy75_dsRGB = NoisyDatasetRGB(img_dir = original_ds_path,\n",
    "                          filenames = original_ds.img_labels,\n",
    "                          noise_lambda = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e252571-1b4d-4e9f-9b89-2768ea495ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "loader = DataLoader(noisy75_ds, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70741a57-e1f4-4bf6-8892-e7ef0d2f4680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 64])\n",
      "With Noise (Left) vs Without Noise (Right) in noisy dataset with lambda = 75\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display images with and without noise\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "print(noisy_imgs[0].size())\n",
    "\n",
    "noisy_img = torch.reshape(noisy_imgs[0], (64, 64, 1))\n",
    "clean_img = torch.reshape(clean_imgs[0], (64, 64, 1))\n",
    "\n",
    "imgs = [noisy_img, clean_img]\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 2, 1\n",
    "for i in range(1, cols * rows + 1):\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(imgs[i-1].squeeze(), cmap=\"grey\")\n",
    "\n",
    "print(\"With Noise (Left) vs Without Noise (Right) in noisy dataset with lambda = 75\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddced7-820f-43ec-9cd0-709d20f9dcae",
   "metadata": {},
   "source": [
    "### Training CNN Autoencoders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec731b6",
   "metadata": {},
   "source": [
    "1. Create a method called \"encode\" in your autoencoder model that accepts the same x (your image) but returns the the z latent space of the model. This is expected to run after you have trained the model for denoising."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f27155-2a27-4e5c-87f2-4f95e1980fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNNAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNAutoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=2, padding=1),  # Example for grayscale images, change channels accordingly\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, 3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, 7)\n",
    "        )\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(64, 32, 7),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid()  # Use sigmoid for [0,1] scaled images\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        z = self.encoder(x)\n",
    "        z = self.relu(z)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa54c56-b146-46b6-a000-2492a1339f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model Func\n",
    "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11728645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model = CNNAutoencoder().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "dataloader = DataLoader(original_ds, batch_size=64, shuffle=True)\n",
    "\n",
    "train_model(model, dataloader, criterion, optimizer, num_epochs=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca117045",
   "metadata": {},
   "source": [
    "2. Using the encode method, create a dataset of z values from the original training set that you used and save it in a .csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f180781",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_encoded_array = []\n",
    "\n",
    "# loop through the original dataset and encode each image then write to csv\n",
    "with open('encoded_images.csv', mode='w', newline='') as csv_file:\n",
    "  csv_writer = csv.writer(csv_file)\n",
    "  for image in original_ds:\n",
    "    z = model.encode(image)\n",
    "    # temp_encoded_array.append(z)\n",
    "    csv_writer.writerow(z)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63829813",
   "metadata": {},
   "source": [
    "## Evaluating results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba93b19b",
   "metadata": {},
   "source": [
    "3. Research a method that determines how good your z features are. You may start with the correlation example: https://colab.research.google.com/drive/1NNH6QBlVZ4SzeLr-hDPYVEoMJ8BnAJYkLinks to an external site.Answer the following question: For this particular task,  how did you measure how good your configuration for latent space dimensionality is? Make sure your answer follows the following criteria:\n",
    "\n",
    "- Objectively sound (computationally proven)\n",
    "- Explainable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a200be83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filters from submission 1\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as pyplot\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"images/noisy.png\")\n",
    "# pyplot.imshow(img)\n",
    "\n",
    "# median filter\n",
    "def median(img):\n",
    "    kernel_size = 3\n",
    "    median_filter = cv.medianBlur(img, kernel_size)\n",
    "    # median_filter = cv.cvtColor(median_filter, cv.COLOR_BGR2GRAY)\n",
    "    return median_filter\n",
    "# pyplot.imshow(median_filter)\n",
    "\n",
    "# mean filter\n",
    "def mean(img):\n",
    "    kernel_size = [3, 3]\n",
    "    mean_filter = cv.blur(img, kernel_size)\n",
    "    # mean_filter = cv.cvtColor(mean_filter, cv.COLOR_BGR2GRAY)\n",
    "    return mean_filter\n",
    "# pyplot.imshow(mean_filter)\n",
    "\n",
    "# bilateral filter\n",
    "def bilat(img):\n",
    "    img_rgb = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    size = 15\n",
    "    sigma_color = 75\n",
    "    sigma_space = 75\n",
    "    bilateral_filter = cv.bilateralFilter(img_rgb, size, sigma_color, sigma_space)\n",
    "    # bilateral_filter = cv.cvtColor(bilateral_filter, cv.COLOR_BGR2GRAY)\n",
    "    return bilateral_filter\n",
    "# pyplot.imshow(bilateral_filter)\n",
    "\n",
    "# gaussian blur filter\n",
    "def gauss(img):\n",
    "    kernel_size = [5, 5]\n",
    "    std_dev = 0 #passing 0 will make function auto compute std dev\n",
    "    gauss_blur = cv.GaussianBlur(img,kernel_size,std_dev)\n",
    "    # gauss_blur = cv.cvtColor(gauss_blur, cv.COLOR_BGR2GRAY)\n",
    "    return gauss_blur\n",
    "# pyplot.imshow(gauss_blur)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195501ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean squared error function from submission 1\n",
    "def mse(img_a, img_b):\n",
    "    h, w = img_a.shape\n",
    "    diff = cv.subtract(img_a, img_b)\n",
    "    err = np.sum(diff**2)\n",
    "    mse = err/(float(h*w))\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c62156",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<0,2,5>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 64\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m img_median \u001b[38;5;241m=\u001b[39m median(image_c)\n\u001b[0;32m     13\u001b[0m img_mean \u001b[38;5;241m=\u001b[39m mean(image_c)\n\u001b[1;32m---> 14\u001b[0m img_bilat \u001b[38;5;241m=\u001b[39m \u001b[43mbilat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_c\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m img_gauss \u001b[38;5;241m=\u001b[39m gauss(image_c)\n\u001b[0;32m     16\u001b[0m median_eval \u001b[38;5;241m=\u001b[39m mse(image_c, img_median)\n",
      "Cell \u001b[1;32mIn[39], line 27\u001b[0m, in \u001b[0;36mbilat\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbilat\u001b[39m(img):\n\u001b[1;32m---> 27\u001b[0m     img_rgb \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2RGB\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[0;32m     29\u001b[0m     sigma_color \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m75\u001b[39m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.8.1) d:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.simd_helpers.hpp:92: error: (-2:Unspecified error) in function '__cdecl cv::impl::`anonymous-namespace'::CvtHelper<struct cv::impl::`anonymous namespace'::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<3,4,-1>,struct cv::impl::A0xd8611878::Set<0,2,5>,3>::CvtHelper(const class cv::_InputArray &,const class cv::_OutputArray &,int)'\n> Invalid number of channels in input image:\n>     'VScn::contains(scn)'\n> where\n>     'scn' is 64\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader(noisy25_ds, batch_size=16)\n",
    "noisy_imgs, clean_imgs = next(iter(loader))\n",
    "\n",
    "noisy_imgs = noisy_imgs.numpy()\n",
    "clean_imgs = clean_imgs.numpy()\n",
    "\n",
    "median_score = 0\n",
    "mean_score = 0\n",
    "bilat_score = 0\n",
    "gauss_score = 0\n",
    "for image_n, image_c in zip(noisy_imgs, clean_imgs):\n",
    "    img_median = median(image_c)\n",
    "    img_mean = mean(image_c)\n",
    "    img_bilat = bilat(image_c)\n",
    "    img_gauss = gauss(image_c)\n",
    "    median_eval = mse(image_c, img_median)\n",
    "    mean_eval = mse(image_c, img_mean)\n",
    "    bilat_eval = mse(image_c, img_bilat)\n",
    "    gauss_eval = mse(image_c, img_gauss)\n",
    "    median_score += median_eval\n",
    "    mean_score += mean_eval\n",
    "    bilat_score += bilat_eval\n",
    "    gauss_score += gauss_eval\n",
    "median_score = median_score/len(noisy_imgs)\n",
    "mean_score = mean_score/len(noisy_imgs)\n",
    "bilat_score = bilat_score/len(noisy_imgs)\n",
    "gauss_score = gauss_score/len(noisy_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341e4495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDIAN eval error:  26.173992555079426\n",
      "MEAN eval error:  27.833290048911397\n",
      "BILATERAL eval error:  25.093905553391334\n",
      "GAUSSIAN eval error:  27.64564125871099\n"
     ]
    }
   ],
   "source": [
    "# use mse function\n",
    "\n",
    "median_eval = mse(img_clear, img_median)\n",
    "print('MEDIAN eval error: ', median_eval)\n",
    "\n",
    "mean_eval = mse(img_clear, img_mean)\n",
    "print('MEAN eval error: ', mean_eval)\n",
    "\n",
    "bilat_eval = mse(img_clear, img_bilat)\n",
    "print('BILATERAL eval error: ', bilat_eval)\n",
    "\n",
    "gauss_eval = mse(img_clear, img_gauss)\n",
    "print('GAUSSIAN eval error: ', gauss_eval)\n",
    "\n",
    "# model25\n",
    "\n",
    "\n",
    "# model50\n",
    "\n",
    "\n",
    "# model75\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
